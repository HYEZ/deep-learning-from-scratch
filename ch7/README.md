## 합성곱 신경망(Convolutional Neural Network)
- `합성곱 계층`과 `풀링 계층`
	- CNN 계층은 Conv-ReLU-(Pooling)
	- 출력에 가까운 층은 지금까지의 Affine-ReLU 구성
	- 마지막 출력 계층은 Affine-Softmax로 구성
- 각 계층 사이에 3차원 데이터같이 입체적인 데이터가 흐른다는 점에서 완전연결(Fully-connected) 신경망과 다름
- 패딩(Padding), 스트라이드(Stride)와 같은 CNN 고유의 용어 등장

### 완전연결(Fully-connected) 계층의 문제점
- 데이터의 형상이 무시됨
	- ex) 데이터가 이미지인 경우 이미지는 가로, 세로, 채널로 구성된 3차원, 하지만 `fully-connected layer`에 입력 시 1차원으로 flatten 해주어야함
	- 하지만 이미지인 경우 이 형상에는 소중한 정보가 담겨있음
		- ex) 공간적으로 가까운 픽셀은 값이 비슷하거나, RGB의 각 채널은 서로 밀접하게 관련됨
		- 3차원 속에서 의미를 갖는 본질적인 패턴이 숨어있음
	- `Fully-connected layer`는 이 성질을 무시하고 `flatten`함

*** 

## 합성곱 계층(Conv)
- 데이터의 형상을 유지함
	- ex) 이미지도 3차원 데이터로 입력받으며, 다음 계층에도 3차원으로 전달함
- 따라서 CNN은 이미지처럼 형상을 가진 데이터를 제대로 이해가능함
- `특징 맵(feature map)`: 합성곱 계층의 입출력 데이터
	- `입력 특징 맵(input feature map)`: 입력 데이터
	- `출력 특징 맵(output feature map)`: 출력 데이터 

### 합성곱 연산
- 필터 연산
- 필터 = 커널
- 필터의 윈도우를 일정 간격으로 이동해가며 입력 데이터에 적용한다음 `단일 곱셈-누산(fused multiply-add, FMA)`
- `필터의 매개변수`가 그동안의 `가중치`의 해당함
- `편향`도 존재, 항상 하나만 존재 (1x1)
- 참고) https://cs231n.github.io/convolutional-networks/

### 패딩(Padding)
- 합성곱 연산을 수행하기 전에 입력데이터의 주변을 0으로 채우는 것
- 주로 출력 크기를 조정할 목적으로 사용함
	- 입력데이터의 공간적 크기를 고정한 채로 다음 계층에 전달하기 위해

### 스트라이드(Stride)
- 필터를 적용하는 간격
- 스트라이드를 키우면 출력의 크기가 작아짐 (반대로 패딩을 크게하면 출력 크기가 늘어남)

### 3차원 데이터의 합성곱 연산
- 각 채널마다 각 필터로 합성곱 연산 수행, 그 결과를 더해서 __하나의 출력__ 을 얻는다.
- __입력 데이터의 채널 수와 필터의 채널 수가 같아야 함__
- 필터 자체의 크기는 원하는 값으로 설정 가능 (단, 모든 채널의 필터가 같은 크기여야 함)
- 블록으로 생각
	- (C, FH, FW)
	- 출력 데이터는 채널이 1인 특징맵 (1, OH, OW)
	- 그렇다면, 출력을 다수의 채널로 어떻게 내보낼까?
		- __필터(가중치)를 여러 개 사용하자!__
			- (C, H, W) * (FN, C, FH, FW) = (FN, OH, OW)
- 합성곱 연산에선 필터의 수도 생각해야 함
	- 보통 필터의 가중치 데이터는 4차원 : (출력 채널 수, 입력 채널 수, 높이, 너비)
- 편향은 (FN, 1, 1)
- 출력 결과는 (FN, OH, OW)

### 배치 처리
- 입력 데이터 : 4차원 -> (데이터 수, 채널 수, 높이, 너비)
- 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개에 대한 합성곱 연산이 수행 (N회 분의 처리를 한번에 수행)

*** 

## 풀링 계층
- 가로, 세로 방향의 공간을 줄이는 연산
- `최대 풀링(max pooling)`과 `평균 풀링(average pooling)`
	- 이미지 인식 분야에서는 최대 풀링 많이 씀
- 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통
- 풀링 계층의 특징
	1. 학습해야 할 매개변수가 없다.
	2. 채널 수가 변하지 않는다.
	3. 입력의 변화에 영향을 적게 받는다(강건하다).